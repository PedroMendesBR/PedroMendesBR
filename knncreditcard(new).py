# -*- coding: utf-8 -*-
"""KNNCreditCard(NEW).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/PedroAugustMendes/Modelo-de-classifica-o-para-an-lise-de-cr-dito/blob/main/KNNCreditCard(NEW).ipynb

# ***Análise possíveis fraudes em cartões de crédito***
"""

#Importação de bibliotecas necessárias.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import sklearn.preprocessing as LabelEncoder

"""##Importação de bibliotecas. Especificando suas utilidades e usabilidades


pandas:

Função: O pandas é uma biblioteca de análise de dados que fornece estruturas de dados e ferramentas para manipulação e análise de dados em Python.
Funcionalidade: Ele oferece estruturas de dados como DataFrames e Series, que facilitam a leitura, manipulação e análise de dados tabulares, como tabelas de banco de dados ou planilhas. O pandas é amplamente usado para preparação de dados e análise exploratória.
numpy:

Função: O NumPy é uma biblioteca numérica para Python que fornece suporte para arrays multidimensionais e funções matemáticas para trabalhar com esses arrays.
Funcionalidade: O NumPy é essencial para computação numérica e científica em Python. Ele oferece eficiência na manipulação de arrays, cálculos matemáticos e álgebra linear, sendo a base para muitas outras bibliotecas científicas em Python.
seaborn:

Função: O Seaborn é uma biblioteca de visualização de dados baseada no matplotlib que fornece uma interface de alto nível para criar gráficos estatísticos atraentes e informativos.
Funcionalidade: O Seaborn simplifica a criação de gráficos estatísticos, como gráficos de dispersão, histogramas, gráficos de barras e muito mais. Ele é especialmente útil para a visualização de dados em análise exploratória e comunicação de resultados.
matplotlib.pyplot:

Função: O matplotlib é uma biblioteca de visualização de dados em Python que oferece controle detalhado sobre gráficos e figuras.
Funcionalidade: O matplotlib.pyplot fornece uma interface de alto nível para criar gráficos e visualizações de dados. Você pode criar gráficos de linha, gráficos de dispersão, gráficos de barra, histogramas e muito mais. É amplamente usado em ciência de dados e análise de dados.
sklearn.preprocessing:

Função: Essa parte do scikit-learn (também conhecido como sklearn) se concentra na pré-processamento de dados, como a normalização e codificação de variáveis.
Funcionalidade: O sklearn.preprocessing oferece várias ferramentas para preparar seus dados antes de aplicar algoritmos de aprendizado de máquina. Isso inclui normalização, escalonamento, codificação de variáveis categóricas, tratamento de valores ausentes e muito mais.

"""

#Fazendo a importação do DataFrame
df = pd.read_csv("/content/sample_data/creditcard.csv")
#Exibindo a dimensão dos dados
print("Dimensão dos dados")
print("Linhas: (Instâncias) | Colunas: (Atributos) ", df.shape)

"""Importação do DataFrame:

df = pd.read_csv("/content/sample_data/creditcard.csv"): Nesta linha, um DataFrame é criado a partir de um arquivo CSV chamado "creditcard.csv". O arquivo é lido e os dados são carregados em um DataFrame chamado df. O caminho para o arquivo é "/content/sample_data/creditcard.csv". Este é um passo comum para carregar dados de um arquivo CSV em um ambiente Python, utilizando a biblioteca pandas.
Exibindo a dimensão dos dados:

print("Dimensão dos dados"): Isso imprime a mensagem "Dimensão dos dados" no console para indicar que a próxima saída se refere à dimensão dos dados.
print("Linhas: (Instâncias) | Colunas: (Atributos) ", df.shape): Esta linha imprime a dimensão dos dados contidos no DataFrame df. O df.shape é uma tupla que retorna o número de linhas (instâncias) e o número de colunas (atributos) no DataFrame. Isso é útil para ter uma ideia do tamanho e estrutura dos dados carregados.
"""

#Exibindo as primeiras 20 linhas da base de dados
df.head(20)

"""Exibição das primeiras 20 linhas da base de dados atráves da utilização da função 'head(x)', onde x é o parâmetro que indica a quantidade de linhas da DataBase que deve ser exibida."""

#Resumo estatístico da variavel amount
print(df['Amount'].describe())

# Histograma da variável 'Amount'
plt.hist(df['Amount'], bins=30, color='blue')
plt.xlabel('Valor da Transação')
plt.ylabel('Contagem')
plt.title('Distribuição de Amount')
plt.show()

# Box plot da variável 'Amount'
sns.boxplot(x='Class', y='Amount', data=df)
plt.xlabel('Classe (0: Não Fraude, 1: Fraude)')
plt.ylabel('Valor da Transação')
plt.title('Box Plot de Amount por Classe')
plt.show()

# Estatísticas descritivas da variável 'Amount' para fraudes
fraud_df = df[df['Class'] == 1]
print(fraud_df['Amount'].describe())

# Correlações lineares de Pearson entre variáveis numéricas e 'Class'
correlation_with_fraud = df.corrwith(df['Class']).sort_values(ascending=False)
print(correlation_with_fraud)

"""A correlação linear é uma medida estatística que avalia a força e a direção do relacionamento entre duas variáveis numéricas. Ela varia de -1 a 1, indicando o grau de associação entre as variáveis. Aqui estão algumas interpretações comuns da correlação linear:

Correlação Positiva (próxima de 1):

Significado: À medida que uma variável aumenta, a outra também tende a aumentar.
Exemplo: Se a correlação entre o tempo gasto online e o valor gasto em compras online é 0,90, isso sugere que, em média, quanto mais tempo alguém passa online, mais dinheiro gasta.
Correlação Negativa (próxima de -1):

Significado: À medida que uma variável aumenta, a outra tende a diminuir.
Exemplo: Se a correlação entre a temperatura externa e o consumo de energia é -0,80, isso indica que, em média, à medida que a temperatura externa sobe, o consumo de energia tende a cair.
Correlação Próxima de 0:

Significado: Não há uma relação linear forte entre as variáveis.
Exemplo: Se a correlação entre a quantidade de café consumida e a probabilidade de chover for 0,05, isso sugere que não há uma relação linear forte entre essas variáveis.
Correlação Perfeita (1 ou -1):

Significado: Existe uma relação linear perfeita entre as variáveis. Isso é extremamente raro na prática.
Exemplo: Se a correlação entre o número de horas de estudo e a nota obtida em um teste for 1, isso significa que, para cada aumento nas horas de estudo, a nota aumenta na mesma proporção.
Significância Estatística:

Além do valor da correlação, é importante verificar se a correlação é estatisticamente significativa. Isso é geralmente feito por meio de testes de hipóteses, como o teste de significância de Pearson (teste t). Valores-p baixos indicam uma correlação estatisticamente significativa.
"""

corr = df['Amount'].corr(df['V1'])
corr

"""O valor de correlação linear de -0.24006877723995812 indica uma correlação linear negativa entre as duas variáveis que estão sendo analisadas. Aqui está como interpretar esse valor:

Correlação Linear Negativa: O sinal negativo (-) indica que as duas variáveis têm uma relação linear negativa. Isso significa que, em geral, quando o valor de uma variável aumenta, o valor da outra variável tende a diminuir, e vice-versa. Em outras palavras, há uma tendência de movimento oposto entre as variáveis.

Magnitude da Correlação: O valor absoluto da correlação (-0.24006877723995812 sem o sinal negativo) varia de 0 a 1, onde 0 representa nenhuma correlação linear e 1 representa uma correlação linear perfeita. Quanto mais próximo o valor estiver de 1 (positivo ou negativo), mais forte é a correlação linear. No seu caso, o valor está relativamente próximo de zero, o que indica uma correlação fraca.

Interpretando a Magnitude: Uma correlação linear negativa com um valor próximo de -1 indicaria uma correlação negativa forte, enquanto um valor próximo de 0 indica uma correlação fraca. Portanto, no seu caso, o valor sugere uma correlação negativa relativamente fraca entre as variáveis.
"""

# Gráfico de barras da distribuição de fraudes ao longo do tempo
fraud_df['Time'].hist(bins=50, color='red')
plt.xlabel('Tempo (segundos)')
plt.ylabel('Contagem de Fraudes')
plt.title('Distribuição de Fraudes ao Longo do Tempo')
plt.show()

# Matriz de correlação de Pearson entre 'Amount' e as componentes principais
correlation_matrix = df[['Amount', 'V1', 'V2', 'V3']].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Matriz de Correlação')
plt.show()

# Fazer um gráfico de dispersão com a linha de regressão
plt.figure(figsize=(8, 6))
sns.regplot(x=df['Amount'], y=df['V1'], data=df, ci=None)
plt.title('Gráfico de Dispersão e Linha de Regressão')
plt.xlabel('Amount')
plt.ylabel('V1')
plt.show()

# Gráfico de barras da variável de resposta 'Class'
df['Class'].value_counts().plot(kind='bar', color='purple')
plt.xlabel('Classe (0: Não Fraude, 1: Fraude)')
plt.ylabel('Contagem')
plt.title('Distribuição da Classe')
plt.show()

# Gráfico de linha para a variável 'Time' ao longo do tempo
plt.plot(df['Time'], df['Amount'], color='red')
plt.xlabel('Tempo (segundos)')
plt.ylabel('Valor da Transação')
plt.title('Variação do Valor da Transação ao Longo do Tempo')
plt.show()

#Verificando a quantidade de elementos (NaN) inválidos estão presentes na base de dados
dados_faltantes = (df.isnull().sum)
print(dados_faltantes)

#Verificando onde os dadso estão faltando
atributos_nulos = df.isnull()
print(atributos_nulos.head(10))

#Criando um novo DataFrame para comparar a DB com e sem valores Nan.
df_2 = df.dropna()
df_2.head(10)

#Comparando as Db - (Linhas, Colunas)
df.shape

df_2.shape

df_2.describe().transpose()

df_2.info()

df_2.hist(figsize = (20,20)) #Cada aba do histograma terá 5 polegadas por 5

import sklearn.preprocessing as StandardScanler
escala = LabelEncoder.StandardScaler()

X = pd.DataFrame(escala.fit_transform(df_2.drop(["Class"],axis = 1)))
y = df_2.Class

X.head(10)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30)

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors= 1)
knn.fit(X_train, y_train)

pred = knn.predict(X_test)

from sklearn.metrics import classification_report, confusion_matrix

print(confusion_matrix(y_test, pred))

print(classification_report(y_test, pred))

error_rate = []

for i in range(1,40):
    knn = KNeighborsClassifier(n_neighbors=i)
    knn.fit(X_train,y_train)
    pred_i = knn.predict(X_test)
    error_rate.append(np.mean(pred_i != y_test))

plt.figure(figsize=(10,6))
plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',
         markerfacecolor='red', markersize=10)
plt.title('Error Rate vs. K Value')
plt.xlabel('K')
plt.ylabel('Error Rate')

knn = KNeighborsClassifier(n_neighbors=1)

knn.fit(X_train,y_train)
pred = knn.predict(X_test)

print('WITH k=1')
print('\n')
print(confusion_matrix(y_test,pred))
print('\n')
print(classification_report(y_test,pred))

from sklearn.metrics import ConfusionMatrixDisplay
import matplotlib.pyplot as plt

conf_matrix = confusion_matrix(y_test, pred)
vis = ConfusionMatrixDisplay(confusion_matrix = conf_matrix,display_labels = [True,False])
vis.plot()
plt.grid(False)
plt.show()